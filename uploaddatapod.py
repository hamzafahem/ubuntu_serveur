import os
import requests
import json
from pathlib import Path
import time
from datetime import datetime

# ============================================================================
# âš™ï¸ CONFIGURATION
# ============================================================================
API_BASE_URL = "http://vps-2865504b.vps.ovh.net:8082/docket/api"
UTILS_API_URL = "http://localhost:8082/api/utils"
JWT_TOKEN = "eyJhbGciOiJIUzI1NiJ9.eyJyb2xlIjoiQURNSU4iLCJzdWIiOiJhZG1pbkBtZWRhZnJpY2EuY29tIiwiaWF0IjoxNzY0MjM0OTk3LCJleHAiOjE3NjQzMjEzOTd9.ILj5BGIQBMR2tWJ0Vn0YYHvbNLS4YnN8WYYOIBWsGZ0"
DEST_DIR = r"C:\Users\Hamza Maanaoui\Desktop\Docket-med_VersionFinalAdapter\DocketFILE"
# r"Z:\Documents\Docket-med_VersionFinalAdapter\Docket-med55\docket-medaf\DossierLTA-POD\dockets"

JSON_HEADERS = {
    "Authorization": f"Bearer {JWT_TOKEN}",
    "accept": "*/*",
    "Content-Type": "application/json"
}

# ============================================================================
# ğŸ“ GÃ‰NÃ‰RATION DU RAPPORT
# ============================================================================
def generate_report(stats_data, output_dir=DEST_DIR):
    """GÃ©nÃ¨re un rapport dÃ©taillÃ© en format texte"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_filename = f"RAPPORT_UPLOAD_{timestamp}.txt"
    report_path = os.path.join(output_dir, report_filename)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("ğŸ“Š RAPPORT D'UPLOAD - DOCKET SYSTEM\n")
        f.write("="*80 + "\n")
        f.write(f"ğŸ“… Date: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
        f.write(f"ğŸ“ RÃ©pertoire: {DEST_DIR}\n")
        f.write("\n")
        
        # STATISTIQUES GÃ‰NÃ‰RALES
        f.write("="*80 + "\n")
        f.write("ğŸ“ˆ STATISTIQUES GÃ‰NÃ‰RALES\n")
        f.write("="*80 + "\n")
        f.write(f"ğŸ“ Dossiers totaux analysÃ©s: {stats_data['total_folders']}\n")
        f.write(f"âœ… Dockets existants dans la base: {stats_data['existing_dockets']}\n")
        f.write(f"ğŸ†• Dockets crÃ©Ã©s: {stats_data['created_dockets']}\n")
        f.write(f"âŒ Dockets non crÃ©Ã©s (Ã©checs): {stats_data['failed_creations']}\n")
        f.write(f"ğŸ“„ Dossiers avec LTA: {stats_data['folders_with_lta']}\n")
        f.write(f"ğŸ“¦ Dossiers avec POD: {stats_data['folders_with_pod']}\n")
        f.write("\n")
        
        # RÃ‰SULTATS UPLOAD
        f.write("="*80 + "\n")
        f.write("ğŸ“¤ RÃ‰SULTATS D'UPLOAD\n")
        f.write("="*80 + "\n")
        f.write(f"âœ… Uploads rÃ©ussis: {stats_data['successful_uploads']}\n")
        f.write(f"âŒ Uploads Ã©chouÃ©s: {stats_data['failed_uploads']}\n")
        f.write(f"ğŸ“‹ Total LTA uploadÃ©s: {stats_data['lta_uploaded']}\n")
        f.write(f"ğŸ“¦ Total POD uploadÃ©s: {stats_data['pod_uploaded']}\n")
        f.write(f"â±ï¸ Temps total: {stats_data['total_time']:.2f} secondes\n")
        f.write(f"âš¡ Vitesse moyenne: {stats_data['avg_speed']:.2f} fichiers/seconde\n")
        f.write("\n")
        
        # DOCKETS NON TROUVÃ‰S
        if stats_data['missing_dockets']:
            f.write("="*80 + "\n")
            f.write("âŒ DOCKETS NON TROUVÃ‰S DANS LA BASE (AVANT CRÃ‰ATION)\n")
            f.write("="*80 + "\n")
            f.write(f"Total: {len(stats_data['missing_dockets'])} dossiers\n")
            f.write("-"*80 + "\n")
            for i, folder in enumerate(stats_data['missing_dockets'], 1):
                f.write(f"{i}. {folder}\n")
            f.write("\n")
        
        # DOCKETS CRÃ‰Ã‰S AVEC SUCCÃˆS
        if stats_data['successfully_created']:
            f.write("="*80 + "\n")
            f.write("âœ… DOCKETS CRÃ‰Ã‰S AVEC SUCCÃˆS\n")
            f.write("="*80 + "\n")
            f.write(f"Total: {len(stats_data['successfully_created'])} dossiers\n")
            f.write("-"*80 + "\n")
            for i, (folder, docket_id) in enumerate(stats_data['successfully_created'], 1):
                f.write(f"{i}. {folder} â†’ ID: {docket_id}\n")
            f.write("\n")
        
        # Ã‰CHECS DE CRÃ‰ATION
        if stats_data['creation_failures']:
            f.write("="*80 + "\n")
            f.write("âŒ Ã‰CHECS DE CRÃ‰ATION DE DOCKETS\n")
            f.write("="*80 + "\n")
            f.write(f"Total: {len(stats_data['creation_failures'])} dossiers\n")
            f.write("-"*80 + "\n")
            for i, folder in enumerate(stats_data['creation_failures'], 1):
                f.write(f"{i}. {folder}\n")
            f.write("\n")
        
        # UPLOADS RÃ‰USSIS
        if stats_data['successful_upload_details']:
            f.write("="*80 + "\n")
            f.write("âœ… DÃ‰TAILS DES UPLOADS RÃ‰USSIS\n")
            f.write("="*80 + "\n")
            f.write(f"Total: {len(stats_data['successful_upload_details'])} fichiers\n")
            f.write("-"*80 + "\n")
            for i, detail in enumerate(stats_data['successful_upload_details'], 1):
                f.write(f"{i}. [{detail['type']}] {detail['folder']} â†’ {detail['file']}\n")
            f.write("\n")
        
        # Ã‰CHECS D'UPLOAD
        if stats_data['failed_upload_details']:
            f.write("="*80 + "\n")
            f.write("âŒ DÃ‰TAILS DES Ã‰CHECS D'UPLOAD\n")
            f.write("="*80 + "\n")
            f.write(f"Total: {len(stats_data['failed_upload_details'])} fichiers\n")
            f.write("-"*80 + "\n")
            for i, detail in enumerate(stats_data['failed_upload_details'], 1):
                f.write(f"{i}. [{detail['type']}] {detail['folder']} â†’ {detail['file']}\n")
                if 'error' in detail:
                    f.write(f"   Erreur: {detail['error']}\n")
            f.write("\n")
        
        # DOSSIERS SANS FICHIERS
        if stats_data['folders_without_files']:
            f.write("="*80 + "\n")
            f.write("âš ï¸ DOSSIERS SANS FICHIERS LTA/POD\n")
            f.write("="*80 + "\n")
            f.write(f"Total: {len(stats_data['folders_without_files'])} dossiers\n")
            f.write("-"*80 + "\n")
            for i, folder in enumerate(stats_data['folders_without_files'], 1):
                f.write(f"{i}. {folder}\n")
            f.write("\n")
        
        f.write("="*80 + "\n")
        f.write("ğŸ“‹ FIN DU RAPPORT\n")
        f.write("="*80 + "\n")
    
    print(f"\nğŸ“ Rapport gÃ©nÃ©rÃ©: {report_filename}")
    return report_path

# ============================================================================
# ğŸ—‚ï¸ MAPPING AUTOMATIQUE
# ============================================================================
def get_docket_mapping_from_api():
    """RÃ©cupÃ¨re le mapping des dockets depuis l'API Spring Boot"""
    url = f"{UTILS_API_URL}/docket-mapping"
    print(f"ğŸ” RÃ©cupÃ©ration du mapping depuis l'API...")
    try:
        response = requests.get(url, headers=JSON_HEADERS, timeout=30)
        if response.status_code == 200:
            data = response.json()
            if data.get("success"):
                mapping = data.get("mapping", {})
                total = data.get("totalDockets", 0)
                print(f"âœ… Mapping rÃ©cupÃ©rÃ©: {total} dockets")
                return mapping
            else:
                print(f"âŒ Erreur API: {data.get('error')}")
                return None
        else:
            print(f"âŒ Erreur HTTP {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ Exception: {e}")
        return None

# ============================================================================
# ğŸ†• CRÃ‰ATION AUTOMATIQUE DE DOCKET
# ============================================================================
def create_docket_from_folder_name(folder_name):
    """CrÃ©e un docket automatiquement depuis le nom du dossier"""
    url = f"{API_BASE_URL}/dockets"
    
    parts = folder_name.split('-')
    
    payload = {
        "docketNumber": folder_name,
        "status": "CREATED",
        "shipper": "AUTO_IMPORT",
        "consignee": "AUTO_IMPORT",
        "origin": parts[0] if len(parts) > 0 else "Unknown",
        "destination": "AUTO",
        "weight": 0.0,
        "volume": 0.0
    }
    
    try:
        response = requests.post(url, headers=JSON_HEADERS, json=payload, timeout=30)
        if response.status_code in (200, 201):
            data = response.json()
            docket_id = data.get('id')
            print(f"   âœ… Docket crÃ©Ã©: ID={docket_id}")
            return docket_id
        else:
            print(f"   âŒ Erreur crÃ©ation: {response.status_code}")
            return None
    except Exception as e:
        print(f"   âŒ Exception: {e}")
        return None

# ============================================================================
# ğŸ”§ CRÃ‰ATION MANUELLE DES 6 DOCKETS PROBLÃ‰MATIQUES
# ============================================================================
def create_missing_dockets_manually():
    """CrÃ©e les 6 dockets problÃ©matiques avec les bons numÃ©ros"""
    
    # Mapping: nom_dossier â†’ vrai_numero_docket (du fichier POD)
    manual_mappings = {
        '135-66526390': '235-66526390',
        '157-08924149': '157-89241493',
        '157-09615372': '157-96153724',
        '157-89241861': '157-89241891',
        '235-03711439': '235-37114394',
        '235-04206346': '235-42063464'
    }
    
    print("\nğŸ”§ CRÃ‰ATION MANUELLE DES 6 DOCKETS PROBLÃ‰MATIQUES")
    print("="*60)
    
    created = []
    failed = []
    
    for folder_name, correct_number in manual_mappings.items():
        print(f"\nğŸ“ Dossier: {folder_name}")
        print(f"   ğŸ”¢ NumÃ©ro correct: {correct_number}")
        
        url = f"{API_BASE_URL}/dockets"
        parts = correct_number.split('-')
        
        payload = {
            "docketNumber": correct_number,
            "status": "CREATED",
            "shipper": "AUTO_IMPORT",
            "consignee": "AUTO_IMPORT",
            "origin": parts[0] if len(parts) > 0 else "Unknown",
            "destination": "AUTO",
            "weight": 0.0,
            "volume": 0.0
        }
        
        try:
            response = requests.post(url, headers=JSON_HEADERS, json=payload, timeout=30)
            if response.status_code in (200, 201):
                data = response.json()
                docket_id = data.get('id')
                print(f"   âœ… Docket crÃ©Ã©: ID={docket_id}")
                created.append((correct_number, docket_id))
            else:
                print(f"   âŒ Erreur {response.status_code}")
                try:
                    error_data = response.json()
                    print(f"   ğŸ’¬ {error_data.get('message', 'Erreur inconnue')}")
                except:
                    pass
                failed.append(correct_number)
        except Exception as e:
            print(f"   âŒ Exception: {e}")
            failed.append(correct_number)
        
        time.sleep(0.3)
    
    print("\n" + "="*60)
    print(f"ğŸ“Š RÃ‰SULTAT: {len(created)} crÃ©Ã©s âœ… | {len(failed)} Ã©checs âŒ")
    print("="*60)
    
    if created:
        print("\nâœ… Dockets crÃ©Ã©s:")
        for num, docket_id in created:
            print(f"   â€¢ {num} â†’ ID: {docket_id}")
    
    if failed:
        print("\nâŒ Ã‰checs:")
        for num in failed:
            print(f"   â€¢ {num}")
    
    return created, failed

# ============================================================================
# ğŸ“¤ UPLOAD ULTIME
# ============================================================================
def upload_document_ultimate(docket_id, document_type, file_path, file_description=""):
    """Solution ultime pour l'upload"""
    try:
        if not os.path.exists(file_path):
            print(f"   âŒ Fichier introuvable: {file_path}")
            return False, "Fichier introuvable"

        file_size = os.path.getsize(file_path) / (1024 * 1024)
        if file_size > 10:
            print(f"   âš ï¸ Fichier trop volumineux ({file_size:.1f}MB)")
            return False, f"Fichier trop volumineux ({file_size:.1f}MB)"

        url = f"{API_BASE_URL}/dockets/{docket_id}/documents?type={document_type}"
        
        if file_description:
            print(f"   ğŸ“¤ {file_description}")

        session = requests.Session()
        session.headers.clear()
        session.headers.update({
            "Authorization": f"Bearer {JWT_TOKEN}",
            "accept": "*/*"
        })

        with open(file_path, 'rb') as f:
            file_content = f.read()

        boundary = "----WebKitFormBoundary7MA4YWxkTrZu0gW"
        body = (
            f"--{boundary}\r\n"
            f'Content-Disposition: form-data; name="file"; filename="{os.path.basename(file_path)}"\r\n'
            f"Content-Type: application/pdf\r\n"
            f"\r\n"
        ).encode('utf-8') + file_content + f"\r\n--{boundary}--\r\n".encode('utf-8')

        headers_manual = {
            "Authorization": f"Bearer {JWT_TOKEN}",
            "accept": "*/*",
            "Content-Type": f"multipart/form-data; boundary={boundary}",
            "Content-Length": str(len(body))
        }

        resp = session.post(url, data=body, headers=headers_manual, timeout=60)

        if resp.status_code in (200, 201):
            print("   âœ… RÃ©ussi")
            return True, None
        else:
            error_msg = f"HTTP {resp.status_code}"
            try:
                error_data = resp.json()
                error_msg = error_data.get('message', error_msg)
            except:
                pass
            print(f"   âŒ Erreur {resp.status_code}")
            return False, error_msg

    except Exception as e:
        print(f"   âŒ Exception: {e}")
        return False, str(e)

# ============================================================================
# ğŸ” ANALYSE COMPLÃˆTE
# ============================================================================
def analyze_all_folders(base_path):
    """Analyse TOUS les dossiers locaux"""
    print("ğŸ” Analyse de TOUS les dossiers locaux...")
    all_folders = [d for d in base_path.iterdir() if d.is_dir()]
    structure_info = {}

    for folder in all_folders:
        folder_name = folder.name.strip()
        structure_info[folder_name] = {
            'lta_file': None,
            'pod_file': None,
            'has_lta': False,
            'has_pod': False
        }

        # LTA
        lta_path = folder / "LTA"
        if lta_path.exists():
            pdf_files = sorted(list(lta_path.glob("*.pdf")) + list(lta_path.glob("*.PDF")))
            if pdf_files:
                structure_info[folder_name]['lta_file'] = pdf_files[0]
                structure_info[folder_name]['has_lta'] = True

        # POD
        pod_path = folder / "POD"
        if pod_path.exists():
            pdf_files = sorted(list(pod_path.glob("*.pdf")) + list(pod_path.glob("*.PDF")))
            if pdf_files:
                structure_info[folder_name]['pod_file'] = pdf_files[0]
                structure_info[folder_name]['has_pod'] = True

    # Statistiques
    total_folders = len(all_folders)
    folders_with_lta = sum(1 for info in structure_info.values() if info['has_lta'])
    folders_with_pod = sum(1 for info in structure_info.values() if info['has_pod'])

    print(f"ğŸ“Š STRUCTURE ANALYSÃ‰E:")
    print(f"   ğŸ“ Dossiers totaux: {total_folders}")
    print(f"   ğŸ“„ Dossiers avec LTA: {folders_with_lta}")
    print(f"   ğŸ“¦ Dossiers avec POD: {folders_with_pod}")

    return structure_info

# ============================================================================
# ğŸ” UPLOAD TOUS LES DOSSIERS (AVEC RAPPORT)
# ============================================================================
def upload_all_folders_with_auto_create():
    """Upload TOUS les dossiers - crÃ©e les dockets manquants + gÃ©nÃ¨re un rapport"""
    base = Path(DEST_DIR)
    if not base.exists():
        print(f"âŒ Dossier source introuvable: {DEST_DIR}")
        return

    # Initialiser les statistiques
    stats = {
        'total_folders': 0,
        'existing_dockets': 0,
        'created_dockets': 0,
        'failed_creations': 0,
        'folders_with_lta': 0,
        'folders_with_pod': 0,
        'successful_uploads': 0,
        'failed_uploads': 0,
        'lta_uploaded': 0,
        'pod_uploaded': 0,
        'total_time': 0,
        'avg_speed': 0,
        'missing_dockets': [],
        'successfully_created': [],
        'creation_failures': [],
        'successful_upload_details': [],
        'failed_upload_details': [],
        'folders_without_files': []
    }

    print("ğŸ”„ RÃ©cupÃ©ration du mapping...")
    docket_mapping = get_docket_mapping_from_api()
    if docket_mapping is None:
        docket_mapping = {}

    # Analyser TOUS les dossiers
    structure_info = analyze_all_folders(base)
    stats['total_folders'] = len(structure_info)
    stats['folders_with_lta'] = sum(1 for info in structure_info.values() if info['has_lta'])
    stats['folders_with_pod'] = sum(1 for info in structure_info.values() if info['has_pod'])

    # PrÃ©parer l'upload
    upload_queue = []
    dockets_to_create = []

    print("\nğŸ” VÃ©rification des dockets...")
    
    for folder_name, folder_info in structure_info.items():
        # VÃ©rifier si le docket existe
        if folder_name not in docket_mapping:
            dockets_to_create.append(folder_name)
            stats['missing_dockets'].append(folder_name)
        else:
            docket_id = docket_mapping[folder_name]
            
            # Ajouter LTA si existe
            if folder_info['has_lta']:
                upload_queue.append({
                    'type': 'LTA',
                    'docket_id': docket_id,
                    'folder_name': folder_name,
                    'file_path': folder_info['lta_file'],
                    'description': f"LTA: {folder_info['lta_file'].name}"
                })

            # Ajouter POD si existe
            if folder_info['has_pod']:
                upload_queue.append({
                    'type': 'POD',
                    'docket_id': docket_id,
                    'folder_name': folder_name,
                    'file_path': folder_info['pod_file'],
                    'description': f"POD: {folder_info['pod_file'].name}"
                })
            
            # VÃ©rifier dossiers sans fichiers
            if not folder_info['has_lta'] and not folder_info['has_pod']:
                stats['folders_without_files'].append(folder_name)

    stats['existing_dockets'] = len(structure_info) - len(dockets_to_create)

    print(f"\nğŸ“Š BILAN:")
    print(f"   âœ… Dockets existants: {stats['existing_dockets']}")
    print(f"   ğŸ†• Dockets Ã  crÃ©er: {len(dockets_to_create)}")
    print(f"   ğŸ“„ Fichiers prÃªts: {len(upload_queue)}")

    # CrÃ©er les dockets manquants
    if dockets_to_create:
        print(f"\nğŸ†• CrÃ©ation de {len(dockets_to_create)} dockets manquants...")
        print(f"ğŸ“‹ Liste des dockets manquants:")
        for i, folder in enumerate(dockets_to_create, 1):
            print(f"   {i}. {folder}")
        
        confirm_create = input("\n   CrÃ©er automatiquement ? (o/N): ").strip().lower()
        
        if confirm_create == 'o':
            for folder_name in dockets_to_create:
                print(f"\nğŸ“ {folder_name}")
                docket_id = create_docket_from_folder_name(folder_name)
                
                if docket_id:
                    stats['created_dockets'] += 1
                    stats['successfully_created'].append((folder_name, docket_id))
                    docket_mapping[folder_name] = docket_id
                    
                    folder_info = structure_info[folder_name]
                    
                    # Ajouter LTA
                    if folder_info['has_lta']:
                        upload_queue.append({
                            'type': 'LTA',
                            'docket_id': docket_id,
                            'folder_name': folder_name,
                            'file_path': folder_info['lta_file'],
                            'description': f"LTA: {folder_info['lta_file'].name}"
                        })
                    
                    # Ajouter POD
                    if folder_info['has_pod']:
                        upload_queue.append({
                            'type': 'POD',
                            'docket_id': docket_id,
                            'folder_name': folder_name,
                            'file_path': folder_info['pod_file'],
                            'description': f"POD: {folder_info['pod_file'].name}"
                        })
                else:
                    stats['failed_creations'] += 1
                    stats['creation_failures'].append(folder_name)
                
                time.sleep(0.3)
            
            print(f"\nâœ… {stats['created_dockets']} dockets crÃ©Ã©s, {stats['failed_creations']} Ã©checs")

    # Afficher rÃ©capitulatif final
    total_lta = sum(1 for item in upload_queue if item['type'] == 'LTA')
    total_pod = sum(1 for item in upload_queue if item['type'] == 'POD')
    
    print(f"\nğŸ“¦ FICHIERS Ã€ UPLOADER:")
    print(f"   ğŸ“ Dossiers: {len(set(item['folder_name'] for item in upload_queue))}")
    print(f"   ğŸ“„ Total fichiers: {len(upload_queue)}")
    print(f"   ğŸ“‹ LTA: {total_lta}")
    print(f"   ğŸ“¦ POD: {total_pod}")

    if not upload_queue:
        print("âŒ Aucun fichier Ã  uploader")
        # GÃ©nÃ©rer rapport mÃªme si pas d'upload
        generate_report(stats)
        return

    # Confirmation upload
    print(f"\nâš ï¸ Vous allez uploader {len(upload_queue)} fichiers")
    confirm = input("   Continuer ? (o/N): ").strip().lower()
    if confirm != 'o':
        print("âŒ AnnulÃ©")
        # GÃ©nÃ©rer rapport partiel
        generate_report(stats)
        return

    # Upload
    print("\nğŸš€ DÃ‰BUT DE L'UPLOAD...")
    print("="*60)
    start_time = time.time()

    for i, item in enumerate(upload_queue, 1):
        print(f"\n[{i}/{len(upload_queue)}] ğŸ“ {item['folder_name']}")
        print(f"   ğŸ†” Docket: {item['docket_id']}")
        
        ok, error = upload_document_ultimate(
            item['docket_id'],
            item['type'],
            item['file_path'],
            item['description']
        )

        if ok:
            stats['successful_uploads'] += 1
            if item['type'] == 'LTA':
                stats['lta_uploaded'] += 1
            else:
                stats['pod_uploaded'] += 1
            
            stats['successful_upload_details'].append({
                'type': item['type'],
                'folder': item['folder_name'],
                'file': item['file_path'].name,
                'docket_id': item['docket_id']
            })
        else:
            stats['failed_uploads'] += 1
            stats['failed_upload_details'].append({
                'type': item['type'],
                'folder': item['folder_name'],
                'file': item['file_path'].name,
                'docket_id': item['docket_id'],
                'error': error
            })

        # Afficher progression toutes les 10 uploads
        if i % 10 == 0:
            elapsed = time.time() - start_time
            avg_speed = i / elapsed if elapsed > 0 else 0
            remaining = len(upload_queue) - i
            eta = remaining / avg_speed if avg_speed > 0 else 0
            print(f"\n   ğŸ“Š Progression: {i}/{len(upload_queue)} ({i*100//len(upload_queue)}%)")
            print(f"   âš¡ Vitesse: {avg_speed:.1f} fichiers/sec")
            print(f"   â±ï¸ Temps restant estimÃ©: {eta/60:.1f} minutes")

        if i % 5 == 0:
            time.sleep(0.5)
        else:
            time.sleep(0.2)

    end_time = time.time()
    stats['total_time'] = end_time - start_time
    if stats['total_time'] > 0:
        stats['avg_speed'] = len(upload_queue) / stats['total_time']

    print("\n" + "="*60)
    print("ğŸ“Š RAPPORT FINAL")
    print("="*60)
    print(f"ğŸ†• Dockets crÃ©Ã©s: {stats['created_dockets']}")
    print(f"âœ… Uploads rÃ©ussis: {stats['successful_uploads']}")
    print(f"âŒ Uploads Ã©chouÃ©s: {stats['failed_uploads']}")
    print(f"ğŸ“‹ LTA uploadÃ©s: {stats['lta_uploaded']}")
    print(f"ğŸ“¦ POD uploadÃ©s: {stats['pod_uploaded']}")
    print(f"ğŸ“„ Total fichiers: {len(upload_queue)}")
    print(f"â±ï¸ Temps total: {stats['total_time']:.1f} secondes ({stats['total_time']/60:.1f} minutes)")
    print(f"âš¡ Vitesse moyenne: {stats['avg_speed']:.2f} fichiers/seconde")

    # GÃ©nÃ©rer le rapport
    report_path = generate_report(stats)
    print(f"\nâœ… Rapport dÃ©taillÃ© sauvegardÃ© dans:")
    print(f"   {report_path}")

# ============================================================================
# ğŸ® MENU PRINCIPAL
# ============================================================================
if __name__ == "__main__":
    print("="*60)
    print("ğŸš€ DOCKET UPLOAD SYSTEM - VERSION COMPLÃˆTE")
    print("="*60)
    print("ğŸ“ RÃ©pertoire:", DEST_DIR)
    print("="*60)
    
    while True:
        print("\nğŸ“‹ MENU PRINCIPAL:")
        print("1. ğŸ“Š Voir les statistiques")
        print("2. ğŸš€ UPLOAD TOUS LES DOSSIERS (avec rapport)")
        print("3. ğŸ”§ CrÃ©er les 6 dockets manuellement")
        print("4. âŒ Quitter")
        
        choice = input("\nVotre choix (1-4): ").strip()
        
        if choice == "1":
            base = Path(DEST_DIR)
            if base.exists():
                analyze_all_folders(base)
            else:
                print(f"âŒ Dossier introuvable: {DEST_DIR}")
            
        elif choice == "2":
            upload_all_folders_with_auto_create()
            
        elif choice == "3":
            create_missing_dockets_manually()
            
        elif choice == "4":
            print("\n" + "="*60)
            print("ğŸ‘‹ Au revoir!")
            print("="*60)
            break
        else:
            print("âŒ Choix invalide, veuillez choisir entre 1 et 4")